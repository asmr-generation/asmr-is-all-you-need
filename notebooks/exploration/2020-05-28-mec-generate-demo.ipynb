{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WaveNet - Generate a Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "#sys.path.append('../../src/')\n",
    "sys.path.append('../../network/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import librosa\n",
    "import librosa.output\n",
    "import datetime\n",
    "import numpy as np\n",
    "from types import SimpleNamespace\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.wavenet.model import WaveNet\n",
    "import models.wavenet.utils.data as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = SimpleNamespace(\n",
    "    layer_size=10,\n",
    "    stack_size=5,\n",
    "    in_channels=256,\n",
    "    res_channels=512,\n",
    "    sample_size=10_000,\n",
    "    sample_rate=22_050,\n",
    "    length=15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator:\n",
    "    def __init__(self, args):\n",
    "        self.args = args\n",
    "\n",
    "        self.wavenet = WaveNet(args.layer_size, args.stack_size,\n",
    "                               args.in_channels, args.res_channels)\n",
    "\n",
    "        self.wavenet.load(args.model_dir, args.model_name, args.step)\n",
    "\n",
    "    @staticmethod\n",
    "    def _variable(data):\n",
    "        tensor = torch.from_numpy(data).float()\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            return torch.autograd.Variable(tensor.cuda())\n",
    "        else:\n",
    "            return torch.autograd.Variable(tensor)\n",
    "\n",
    "    def _make_seed(self, audio):\n",
    "        audio = np.pad([audio], [[0, 0], [self.wavenet.receptive_fields, 0], [0, 0]], 'constant')\n",
    "\n",
    "        if self.args.sample_size:\n",
    "            seed = audio[:, :self.args.sample_size, :]\n",
    "        else:\n",
    "            seed = audio[:, :self.wavenet.receptive_fields*2, :]\n",
    "\n",
    "        return seed\n",
    "\n",
    "    def _get_seed_from_audio(self, filepath):\n",
    "        audio = utils.load_audio(filepath, self.args.sample_rate)\n",
    "        audio_length = len(audio)\n",
    "\n",
    "        audio = utils.mu_law_encode(audio, self.args.in_channels)\n",
    "        audio = utils.one_hot_encode(audio, self.args.in_channels)\n",
    "\n",
    "        seed = self._make_seed(audio)\n",
    "\n",
    "        return self._variable(seed), audio_length\n",
    "\n",
    "    def _save_to_audio_file(self, data):\n",
    "        data = data[0].cpu().data.numpy()\n",
    "        data = utils.one_hot_decode(data, axis=1)\n",
    "        audio = utils.mu_law_decode(data, self.args.in_channels)\n",
    "\n",
    "        librosa.output.write_wav(self.args.out, np.array(audio, dtype=\"float32\", self.args.sample_rate)\n",
    "        print('Saved wav file at {}'.format(self.args.out))\n",
    "\n",
    "        return audio#librosa.get_duration(y=audio, sr=self.args.sample_rate)\n",
    "\n",
    "    def generate(self):\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = []\n",
    "            inputs, audio_length = self._get_seed_from_audio(self.args.seed)\n",
    "\n",
    "            while True:\n",
    "                new = self.wavenet.generate(inputs)\n",
    "\n",
    "                outputs = torch.cat((outputs, new), dim=1) if len(outputs) else new\n",
    "\n",
    "                print('{0}/{1} samples are generated.'.format(len(outputs[0]), self.args.length*self.args.sample_rate))\n",
    "\n",
    "                if len(outputs[0]) >= self.args.length*self.args.sample_rate:\n",
    "                    break\n",
    "\n",
    "                inputs = torch.cat((inputs[:, :-len(new[0]), :], new), dim=1)\n",
    "\n",
    "            outputs = outputs[:, :audio_length, :]\n",
    "\n",
    "        return self._save_to_audio_file(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "params.model_dir = '../../network/weights/wavenet/'\n",
    "params.model_name = 'wavenet-tapping-glass-tiny-jar'\n",
    "params.step = 0\n",
    "params.seed = '../../data/processed/tapping/tapping-glass/PLhDdb5CgZ4-tiny-jar.wav'\n",
    "params.out = '../../network/outputs/wavenet/wavenet-out-tapping-glass-tiny-jar.wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 GPUs are detected.\n",
      "Loading model from ../../network/weights/wavenet/\n",
      "../../data/processed/tapping/tapping-glass/PLhDdb5CgZ4-tiny-jar.wav\n",
      "4885/752000 samples are generated.\n",
      "9770/752000 samples are generated.\n",
      "14655/752000 samples are generated.\n",
      "19540/752000 samples are generated.\n",
      "24425/752000 samples are generated.\n",
      "29310/752000 samples are generated.\n",
      "34195/752000 samples are generated.\n",
      "39080/752000 samples are generated.\n",
      "43965/752000 samples are generated.\n",
      "48850/752000 samples are generated.\n",
      "53735/752000 samples are generated.\n",
      "58620/752000 samples are generated.\n",
      "63505/752000 samples are generated.\n",
      "68390/752000 samples are generated.\n",
      "73275/752000 samples are generated.\n",
      "78160/752000 samples are generated.\n",
      "83045/752000 samples are generated.\n",
      "87930/752000 samples are generated.\n",
      "92815/752000 samples are generated.\n",
      "97700/752000 samples are generated.\n",
      "102585/752000 samples are generated.\n",
      "107470/752000 samples are generated.\n",
      "112355/752000 samples are generated.\n",
      "117240/752000 samples are generated.\n",
      "122125/752000 samples are generated.\n",
      "127010/752000 samples are generated.\n",
      "131895/752000 samples are generated.\n",
      "136780/752000 samples are generated.\n",
      "141665/752000 samples are generated.\n",
      "146550/752000 samples are generated.\n",
      "151435/752000 samples are generated.\n",
      "156320/752000 samples are generated.\n",
      "161205/752000 samples are generated.\n",
      "166090/752000 samples are generated.\n",
      "170975/752000 samples are generated.\n",
      "175860/752000 samples are generated.\n",
      "180745/752000 samples are generated.\n",
      "185630/752000 samples are generated.\n",
      "190515/752000 samples are generated.\n",
      "195400/752000 samples are generated.\n",
      "200285/752000 samples are generated.\n",
      "205170/752000 samples are generated.\n",
      "210055/752000 samples are generated.\n",
      "214940/752000 samples are generated.\n",
      "219825/752000 samples are generated.\n",
      "224710/752000 samples are generated.\n",
      "229595/752000 samples are generated.\n",
      "234480/752000 samples are generated.\n",
      "239365/752000 samples are generated.\n",
      "244250/752000 samples are generated.\n",
      "Saved wav file at ../../network/outputs/wavenet/wavenet-out-tapping-glass.wav\n"
     ]
    }
   ],
   "source": [
    "generator = Generator(params)\n",
    "x = generator.generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1036350,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed, sr = librosa.load(params.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = seed.copy()\n",
    "audio[:len(x)] = x\n",
    "audio = audio[:len(x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio.__class__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.output.write_wav(params.out, audio, params.sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
