{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WaveNet - Fit a Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "#sys.path.append('../../src/')\n",
    "sys.path.append('../../network/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from types import SimpleNamespace\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.wavenet_no_padding.model import WaveNet\n",
    "from models.wavenet_no_padding.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = SimpleNamespace(\n",
    "    layer_size=10,\n",
    "    stack_size=5,\n",
    "    in_channels=256,\n",
    "    res_channels=512,\n",
    "    lr=2e-3,\n",
    "    sample_size=15_000,\n",
    "    sample_rate=22_050,\n",
    "    epochs=10_000,\n",
    "    model_dir='../../network/weights/wavenet/'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self,\n",
    "                 layer_size: int = 10,\n",
    "                 stack_size: int = 5,\n",
    "                 in_channels: int = 256,\n",
    "                 res_channels: int = 512,\n",
    "                 lr: float = 2e-3,\n",
    "                 sample_size: int = 100_000,\n",
    "                 sample_rate: int =22_050,\n",
    "                 epochs: int = 10_000,\n",
    "                 data_dir: str = '.',\n",
    "                 model_dir: str = './',\n",
    "                 model_name: str = None):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        self.epochs = epochs\n",
    "        self.model_dir = model_dir\n",
    "        self.model_name = model_name\n",
    "        \n",
    "        self.wavenet = WaveNet(layer_size, stack_size, in_channels, res_channels, lr=lr)\n",
    "        self.data_loader = DataLoader(data_dir, self.wavenet.receptive_fields,\n",
    "                                      sample_size, sample_rate, in_channels)\n",
    "\n",
    "    def infinite_batch(self):\n",
    "        while True:\n",
    "            for dataset in self.data_loader:\n",
    "                for inputs, targets in dataset:\n",
    "                    yield inputs, targets\n",
    "\n",
    "    def run(self):\n",
    "        total_steps = 0\n",
    "\n",
    "        for inputs, targets in self.infinite_batch():\n",
    "            loss = self.wavenet.train(inputs, targets)\n",
    "\n",
    "            total_steps += 1\n",
    "\n",
    "            print('[{0}/{1}] loss: {2}'.format(total_steps, self.epochs, loss))\n",
    "\n",
    "            if total_steps > self.epochs:\n",
    "                break\n",
    "\n",
    "            if total_steps % 200 == 0:\n",
    "                self.wavenet.save(self.model_dir, self.model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#params.data_dir = '../../data/processed/tapping/tapping-glass/partial/'\n",
    "#params.model_name = 'wavenet-tapping-glass-tiny-jar-2'\n",
    "params.data_dir = '../../data/processed/brushing/brushing-rode-mic/partial/'\n",
    "params.model_name = 'wavenet-brushing-rode-mic-nn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 GPUs are detected.\n",
      "../../data/processed/brushing/brushing-rode-mic/partial/H2Cam080Ye8-silicon-brush-Copy1.wav\n",
      "<class 'numpy.ndarray'>\n",
      "15000\n",
      "[1/10000] loss: 5.5451202392578125\n",
      "[2/10000] loss: 5.5448808670043945\n",
      "[3/10000] loss: 5.544785499572754\n",
      "[4/10000] loss: 5.544907093048096\n",
      "[5/10000] loss: 5.54452657699585\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(**params.__dict__)\n",
    "#trainer.wavenet.load(params.model_dir, params.model_name)\n",
    "trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GENERATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.wavenet_no_padding.model import WaveNet\n",
    "import models.wavenet_no_padding.utils.data as utils\n",
    "\n",
    "import torch\n",
    "import librosa\n",
    "import librosa.output\n",
    "import datetime\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = SimpleNamespace(\n",
    "    layer_size=10,\n",
    "    stack_size=5,\n",
    "    in_channels=256,\n",
    "    res_channels=512,\n",
    "    sample_size=25_000,\n",
    "    sample_rate=22_050,\n",
    "    length=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator:\n",
    "    def __init__(self, args):\n",
    "        self.args = args\n",
    "\n",
    "        self.wavenet = WaveNet(args.layer_size, args.stack_size,\n",
    "                               args.in_channels, args.res_channels)\n",
    "\n",
    "        self.wavenet.load(args.model_dir, args.model_name, args.step)\n",
    "\n",
    "    @staticmethod\n",
    "    def _variable(data):\n",
    "        tensor = torch.from_numpy(data).float()\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            return torch.autograd.Variable(tensor.cuda())\n",
    "        else:\n",
    "            return torch.autograd.Variable(tensor)\n",
    "\n",
    "    def _make_seed(self, audio):\n",
    "        audio = np.pad([audio], [[0, 0], [0, 0], [0, 0]], 'constant')\n",
    "\n",
    "        if self.args.sample_size:\n",
    "            seed = audio[:, :self.args.sample_size, :]\n",
    "        else:\n",
    "            seed = audio[:, :self.wavenet.receptive_fields*2, :]\n",
    "\n",
    "        return seed\n",
    "\n",
    "    def _get_seed_from_audio(self, filepath):\n",
    "        audio = utils.load_audio(filepath, self.args.sample_rate)\n",
    "        i = random.choice(np.arange(0, len(audio)-self.wavenet.receptive_fields))\n",
    "        audio = audio[i:]\n",
    "        audio_length = len(audio)\n",
    "\n",
    "        audio = utils.mu_law_encode(audio, self.args.in_channels)\n",
    "        audio = utils.one_hot_encode(audio, self.args.in_channels)\n",
    "\n",
    "        seed = self._make_seed(audio)\n",
    "\n",
    "        return self._variable(seed), audio_length\n",
    "\n",
    "    def _save_to_audio_file(self, data):\n",
    "        data = data[0].cpu().data.numpy()\n",
    "        print(data.shape)\n",
    "        data = utils.one_hot_decode(data, axis=1)\n",
    "        audio = utils.mu_law_decode(data, self.args.in_channels)\n",
    "\n",
    "        librosa.output.write_wav(self.args.out, np.array(audio, dtype=\"float32\"), self.args.sample_rate)\n",
    "        print('Saved wav file at {}'.format(self.args.out))\n",
    "\n",
    "        return audio#librosa.get_duration(y=audio, sr=self.args.sample_rate)\n",
    "\n",
    "    def generate(self):\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = []\n",
    "            inputs, audio_length = self._get_seed_from_audio(self.args.seed)\n",
    "\n",
    "            while True:\n",
    "                new = self.wavenet.generate(inputs)\n",
    "\n",
    "                outputs = torch.cat((outputs, new), dim=1) if len(outputs) else new\n",
    "\n",
    "                print('{0}/{1} samples are generated.'.format(len(outputs[0]), self.args.length*self.args.sample_rate))\n",
    "\n",
    "                if len(outputs[0]) >= self.args.length*self.args.sample_rate:\n",
    "                    break\n",
    "\n",
    "                inputs = torch.cat((inputs[:, :-len(new[0]), :], new), dim=1)\n",
    "\n",
    "            outputs = outputs[:, :self.args.length*self.args.sample_rate, :]\n",
    "\n",
    "        return self._save_to_audio_file(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "params.model_dir = '../../network/weights/wavenet/'\n",
    "params.model_name = 'wavenet-tapping-glass-no-padding-no-determ'\n",
    "params.step = 0\n",
    "params.seed = '../../data/processed/tapping/tapping-glass/PLhDdb5CgZ4-hour-glass.wav'\n",
    "params.out = '../../network/outputs/wavenet/wavenet-out-tapping-glass-hour-glass-nn-2.wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 GPUs are detected.\n",
      "Loading model from ../../network/weights/wavenet/\n",
      "../../data/processed/tapping/tapping-glass/PLhDdb5CgZ4-hour-glass.wav\n",
      "19885/220500 samples are generated.\n",
      "39770/220500 samples are generated.\n",
      "59655/220500 samples are generated.\n",
      "79540/220500 samples are generated.\n",
      "99425/220500 samples are generated.\n",
      "119310/220500 samples are generated.\n",
      "139195/220500 samples are generated.\n",
      "159080/220500 samples are generated.\n",
      "178965/220500 samples are generated.\n",
      "198850/220500 samples are generated.\n",
      "218735/220500 samples are generated.\n",
      "238620/220500 samples are generated.\n",
      "(220500, 256)\n",
      "Saved wav file at ../../network/outputs/wavenet/wavenet-out-tapping-glass-hour-glass-nn-2.wav\n"
     ]
    }
   ],
   "source": [
    "generator = Generator(params)\n",
    "x = generator.generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
